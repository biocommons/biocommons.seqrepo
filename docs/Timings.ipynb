{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Collection Timing Comparisons\n",
    "\n",
    "This notebook compares timings for fetching short random genomic slices from GRCh38 using:\n",
    "\n",
    "* SeqRepo native python interface (local sequences)\n",
    "* SeqRepo REST interface (local sequences)\n",
    "* ENA CRAM implementation of refget (the only public facility with human sequences at this time)\n",
    "* NCBI E-utilities\n",
    "\n",
    "The goal of these timings is to provide order-of-magnitude differences between the methods. No effort has been made to optimize any of these timings or to seek attain high-precision timings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fetch methods\n",
    "\n",
    "For each of the above sources, a `fetch_<method>(accession, start, end)` method is defined below. Those methods are excuted using a single timing harness at the bottom of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import urlsafe_b64decode, urlsafe_b64encode\n",
    "from binascii import hexlify, unhexlify\n",
    "import functools\n",
    "import hashlib\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import requests\n",
    "\n",
    "from biocommons.seqrepo import SeqRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48380452/mask-out-sensitive-information-in-python-log\n",
    "    \n",
    "_logger = logging.getLogger(__name__)\n",
    "\n",
    "class RedactingFormatter(logging.Formatter):\n",
    "    \"\"\"Formatter that removes sensitive information in urls.\"\"\"\n",
    "    @staticmethod\n",
    "    def _filter(s):\n",
    "        return \n",
    "                      \n",
    "    def format(self, record):\n",
    "        s = logging.Formatter.format(self, record)\n",
    "        s = re.sub(r\"(ncbi_api_key|ncbi_api_tool|ncbi_api_email)=[^&]+\", r\"\\1=â€¦\", s)\n",
    "        return s\n",
    "\n",
    "for handler in _logger.root.handlers:\n",
    "    handler.setFormatter(RedactingFormatter(handler.formatter._fmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup fetch_seqrepo_python()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = SeqRepo(\"/usr/local/share/seqrepo/latest\")\n",
    "\n",
    "def fetch_seqrepo_python(accession, start=None, end=None):\n",
    "    return sr.fetch(accession, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fetch_seqrepo_rest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqrepo_base_url = \"http://localhost:5000/seqrepo/1/\"\n",
    "seqrepo_session = requests.Session()\n",
    "seqrepo_session.request = functools.partial(seqrepo_session.request, timeout=2.0)\n",
    "\n",
    "def fetch_seqrepo_rest(accession, start=None, end=None):\n",
    "    url = seqrepo_base_url + \"sequence/\" + accession\n",
    "    params = {\n",
    "        \"start\": start,\n",
    "        \"end\": end\n",
    "    }\n",
    "    resp = seqrepo_session.get(url, params=params)\n",
    "    resp.raise_for_status()\n",
    "    return resp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup fetch_refget_ena()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refget_session = requests.Session()\n",
    "refget_session.request = functools.partial(refget_session.request, timeout=2.0)\n",
    "refget_session.params.update({\n",
    "    \"accept\": \"text/plain\"\n",
    "})\n",
    "\n",
    "refget_base_url = \"https://www.ebi.ac.uk/ena/cram/sequence\"\n",
    "    \n",
    "def fetch_refget_ena(md5, start=None, end=None):\n",
    "    url = refget_base_url + \"/\" + md5\n",
    "    params = {}\n",
    "    if start:\n",
    "        params[\"start\"] = start\n",
    "    if end:\n",
    "        params[\"end\"] = end\n",
    "    resp = refget_session.get(url, params=params)\n",
    "    resp.raise_for_status()\n",
    "    return resp.text    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fetch_ncbi_eutils()\n",
    "Get an NCBI API key at https://www.ncbi.nlm.nih.gov/account/settings/, then create `~/.config/ncbi.json` with this template:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"ncbi_api_key\": \"3a5...910\",\n",
    "  \"ncbi_api_tool\": \"my tool\",\n",
    "  \"ncbi_api_email\": \"myemail\"\n",
    "}\n",
    "```\n",
    "\n",
    "In practice, NCBI services exhibit sporadic errors that succeed with immediate retry and appear to be unrelated to rate limiting. Therefore, this function is more complicated than the others because it attempts to provide rate limiting and retry logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_credentials_fn = os.path.expanduser(\"~/.credentials/ncbi.json\")\n",
    "ncbi_credentials = json.load(open(ncbi_credentials_fn))\n",
    "\n",
    "efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "rate_limit = 10                       # queries/sec\n",
    "query_period = 1.0/rate_limit         # period between queries\n",
    "\n",
    "ncbi_session = requests.Session()\n",
    "ncbi_session.request = functools.partial(ncbi_session.request, timeout=2.0)\n",
    "ncbi_session.params.update({\n",
    "    \"db\": \"nucleotide\",\n",
    "    \"rettype\": \"fasta\",\n",
    "    \"retmode\": \"text\"})\n",
    "ncbi_session.params.update(ncbi_credentials)\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "ncbi_session.mount(\"https://\", HTTPAdapter(max_retries=3))\n",
    "\n",
    "ncbi_last_query_time = 0\n",
    "def fetch_ncbi_eutils(accession, start=None, end=None):\n",
    "    global ncbi_last_query_time\n",
    "    params = {\"id\": accession}\n",
    "    if start:\n",
    "        params[\"seq_start\"] = start + 1\n",
    "    if end:\n",
    "        params[\"seq_stop\"] = end\n",
    "    time_now = time.time()\n",
    "    sleep_time = max(0, ncbi_last_query_time + query_period - time_now)\n",
    "    time.sleep(sleep_time)\n",
    "    ncbi_last_query_time = time_now\n",
    "    resp = ncbi_session.get(efetch_url, params=params)\n",
    "    resp.raise_for_status()\n",
    "    fasta = resp.text\n",
    "    return fasta[fasta.find(\"\\n\")+1:].replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build sequence slice expressions\n",
    "The goal is to build a list of sequence slices -- short random excerpts of GRCh38. All fetch methods will be called with the same slices. (ENA refget understands only md5 sequence identifiers, so the refseq accessions are translated ahead of time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acs: list of grch38 primary accession refseq ids\n",
    "acs = [\n",
    "    'NC_000001.11', 'NC_000002.12', 'NC_000003.12', 'NC_000004.12', 'NC_000005.10',\n",
    "    'NC_000006.12', 'NC_000007.14', 'NC_000008.11', 'NC_000009.12', 'NC_000010.11',\n",
    "    'NC_000011.10', 'NC_000012.12', 'NC_000013.11', 'NC_000014.9',  'NC_000015.10',\n",
    "    'NC_000016.10', 'NC_000017.11', 'NC_000018.10', 'NC_000019.10', 'NC_000020.11',\n",
    "    'NC_000021.9',  'NC_000022.11', 'NC_000023.11', 'NC_000024.10']\n",
    "\n",
    "# ac_lengths = {refseq_ac: sequence length} (from SeqRepo metadata)\n",
    "ac_lengths = {ac: len(sr[ac]) for ac in acs}\n",
    "\n",
    "def lookup_md5(sr, ac):\n",
    "    s = [a for a in sr[ac].aliases if a.startswith(\"MD5:\")][0]\n",
    "    return s[4:]\n",
    "\n",
    "# ac_md5s = {refseq_ac: md5} (from SeqRepo aliases)\n",
    "ac_md5s = {ac: lookup_md5(sr, ac) for ac in acs}\n",
    "\n",
    "# build two sets of equivalent slices, one with refseq accession, the other with md5 (for refget)\n",
    "def random1():\n",
    "    max_size = 25\n",
    "    ac = random.choice(acs)\n",
    "    start = random.randint(0, ac_lengths[ac] - max_size)\n",
    "    end = start + random.randint(1, 20)\n",
    "    return (ac, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "def time1(fx, slices):\n",
    "    \"\"\"execute fx on each s in slices, returning tuple of (elapsed time, n_exceptions)\n",
    "    \n",
    "    elapsed time (rather than cpu time) is used because elapsed time is a\n",
    "    better proxy for user experience\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def exec1(fx, s):\n",
    "        try:\n",
    "            return fx(*s)\n",
    "        except (RequestException) as e:\n",
    "            return e\n",
    "    \n",
    "    t0 = time.time()\n",
    "    res = [exec1(fx, s) for s in slices]\n",
    "    tdelta = time.time() - t0\n",
    "    errors = [r for r in res if isinstance(r, Exception)]\n",
    "    error_counts = collections.Counter(type(e) for e in errors)\n",
    "    return {\n",
    "        \"etime\": tdelta,\n",
    "        \"errors\": error_counts.most_common(),\n",
    "        \"n_errors\": len(errors),\n",
    "        \"throughput\": len(slices)/tdelta\n",
    "        }\n",
    "\n",
    "\n",
    "def time_all(n_slices):\n",
    "    refseq_slices = [random1() for _ in range(n_slices)]\n",
    "    md5_slices = [(ac_md5s[rs[0]], rs[1], rs[2]) for rs in refseq_slices]\n",
    "    results = {\n",
    "        \"ncbi_eutils\": time1(fetch_ncbi_eutils, refseq_slices),\n",
    "        \"refget_ena\": time1(fetch_refget_ena, md5_slices),\n",
    "        \"seqrepo_python\": time1(fetch_seqrepo_python, refseq_slices),\n",
    "        \"seqrepo_rest\": time1(fetch_seqrepo_rest, refseq_slices)\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# smoke test: fetch 1 random sequence slice\n",
    "time_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run timing tests on 1000 random sequence slices\n",
    "# N.B. The timings reported in the manuscript were generated on two environments:\n",
    "# NCBI E-utilities and ENA refget timings were generated on a c4.large instance in AWS\n",
    "# SeqRepo Python and REST timings were generated on a laptop with SSD\n",
    "# time_all(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
